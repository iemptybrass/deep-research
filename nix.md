# Optimizing Nix Evaluation and Rebuild Performance

## Introduction  
Nix is a pure and lazy functional language used to define packages and configurations. Lazy evaluation means Nix only evaluates expressions when needed, which can greatly improve efficiency ([The Basics of the Language - Nix Pills](https://nixos.org/guides/nix-pills/04-basics-of-language#:~:text=Nix%20evaluates%20expressions%20only%20when,feature%20when%20working%20with%20packages)). However, as Nix codebases (like Nixpkgs or NixOS configurations) grow to thousands of attributes, evaluation can become a bottleneck. For instance, listing all packages took under 3 seconds in Nixpkgs 16.03, but over 15 seconds by 24.05 ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=For%20instance%2C%20listing%20all%20packages,when%20running%20nix%20flake%20check)). To keep Nix evaluations fast and rebuilds minimal, it’s crucial to use language constructs with care. This report analyzes Nix syntax features – such as `let…in`, `with`, `inherit`, `rec`, lazy attribute sets, lambda functions (inline vs. named), default arguments, modular imports, and explicit argument passing – and their impact on performance, laziness (thunk creation and sharing), memoization, reusability, readability, and build caching. Both theoretical behavior and practical benchmarks (using pure Nix evaluation via `nix eval/build/instantiate`) are included to guide best practices.

## Lazy Evaluation and Thunks in Nix  
Nix employs *lazy evaluation*: an expression is not computed until its value is needed. Internally, Nix delays computations using *thunks* (deferred computations) ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=In%20Nix%2C%20thunks%20are%20used,It%20consists%20of)). A thunk holds the expression and its environment (the variables in scope) ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=There%20is%20one%20exception%2C%20however%2C,of%20two%20pieces%20of%20information)) and is evaluated at most once – when first needed – then replaced with its result. Subsequent uses of that value reuse the computed result. For example, in: 

```nix
let  
  x = 2 * 3;  
in x + x
``` 

the expression `2*3` is stored in a thunk bound to `x` and will be evaluated only on demand. Once `x` is needed, Nix computes `2*3 = 6` and any further use of `x` sees the final value 6 without recomputation ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=If%20,3%2C%20and%20thunk%20is%20overwritten)). If `x` is never needed, the multiplication is never executed at all.

**When are thunks created?** Nix avoids thunks for trivial cases: literal values (integers, strings, booleans, etc.) produce no thunk since there’s nothing to delay, and simply referencing an already-bound variable doesn’t create a new thunk ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=2,for%20referenced%20variables)). However, Nix *will* create thunks for more complex expressions: each element of a list, each attribute value in a set, each function application argument, and each default value in a function parameter (if not provided) is wrapped in a thunk (unless it’s a simple literal or direct variable) ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=3,a%20default%20value%20which%20doesn%27t)). For instance, in a `let` binding `y = "Hello, " + name;`, the concatenation creates a thunk because it’s not a plain value ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=,Paul)). Similarly, an attribute defined as `foo = 1 + 1;` would be a thunk in an attrset until needed. On the other hand, referencing a variable like `result = y;` does not add another thunk ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=,Paul)). This lazy-by-default behavior means large portions of Nix code can be defined without immediate cost – only the parts that are accessed will incur evaluation time. This is why Nixpkgs can define thousands of packages lazily and still quickly access one package on demand ([The Basics of the Language - Nix Pills](https://nixos.org/guides/nix-pills/04-basics-of-language#:~:text=Nix%20evaluates%20expressions%20only%20when,feature%20when%20working%20with%20packages)).

**Sharing and memoization:** One important consequence of Nix’s laziness is that any given thunk is evaluated at most once. If you use the same computed value multiple times and it’s stored in a variable (or attribute), Nix will *memoize* that result after the first evaluation. For example, in the code above, `x + x` does **not** perform the multiplication twice – the result of `x` is computed once and reused. In practice, this means we can manually memoize expensive computations by binding them to variables in a high-level scope. If we fail to do so (e.g. writing an expensive expression twice), Nix will treat each occurrence as a separate thunk and may recompute it. Nix does **not** automatically recognize identical sub-expressions and share them (it has no general “common subexpression elimination” or *maximal laziness* optimization) ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=Image%20shlevy%3A)). A user on NixOS Discourse demonstrated this by computing a large list of prime numbers: when the code was structured to reuse a single `primes` list, computing an element twice was as fast as once (~1.90s in both cases) ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=%24%20time%20nix%20eval%20,arg%20num%2020000%20224743)), but when that sharing was removed, doing the computation twice took roughly twice as long ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=Image%20shlevy%3A)). The takeaway is clear: **if you need to use the same result in multiple places, bind it to a `let` variable or an attribute so that Nix will evaluate it once and memoize it** ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=shlevy%20%20February%203%2C%202019%2C,1%3A01am%20%206)) ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=Image%20shlevy%3A)). Conversely, writing the same complex expression in multiple spots without a common binding will cause repeated work.

**Thunks and memory:** Laziness can trade time for memory. Each thunk allocation carries overhead (a small 24-byte structure in the evaluator) ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=In%20the%20Nix%20evaluator%2C%20every,%E2%80%9D%20For%20example%2C%20the%20attribute)), and thunks hold references to their scope, preventing garbage collection of those scope variables until the thunk is evaluated or discarded ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=It%20is%20very%20easy%20to,which%20can%20have%20negative%20consequences)). Creating huge numbers of thunks (for instance, an attrset with thousands of large expressions all left unevaluated) can increase memory usage and even risk stack overflow if very deeply nested ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=It%20is%20very%20easy%20to,which%20can%20have%20negative%20consequences)). Therefore, while laziness avoids unnecessary computations, one should be mindful of assembling very large lazy structures. If you have an extremely large list or attrset but only need a small part of it, it’s efficient in runtime, but it does allocate thunks for each element/attribute. Recent Nix improvements have looked into *lazy attribute loading* to mitigate this overhead (e.g. making even the creation of attribute lists lazy), but by default all attribute names and the presence of their thunks are realized when the set is evaluated, even if their values remain unevaluated ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=,)). In summary, laziness gives great performance benefits by skipping unused work, but careful structuring and sharing of needed results are key to avoid the flip side of too many thunks or duplicate evaluations.

## Scoping Constructs: `let`, `with`, `inherit`, and `rec`  

### `let … in` Bindings  
The `let … in` construct allows introducing local variables (bindings) for use in an expression. It’s a fundamental tool for both performance and readability in Nix. Variables defined in a `let` are evaluated lazily, but once evaluated they are reused without recomputation. Importantly, referencing a let-bound variable does **not** incur a thunk of its own – Nix uses the value (or thunk) already stored in that variable ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=2,for%20referenced%20variables)). This makes `let` ideal for avoiding repetitive calculations. For example: 

```nix
let 
  bigList = [1..1000000];   # expensive to build 
in 
  { subset1 = builtins.tail 999900 bigList;
    subset2 = builtins.take 100 bigList; }
``` 

Here `bigList` will be constructed at most once, even though it’s used twice, because it’s bound to a name. Without the `let`, if we inlined the list literal in both `tail` and `take`, Nix would create two large thunks (and would have to build the list twice when needed). Thus, **using `let` to bind sub-expressions improves evaluation speed by sharing results** ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=If%20,3%2C%20and%20thunk%20is%20overwritten)), often turning what would be exponential or repeated work into a one-time cost.

In practice, you should introduce a `let` binding for any non-trivial expression that is used more than once or whose value is needed across multiple parts of a configuration. This also aids readability by giving a meaningful name to the expression. Another benefit is isolating changes: if you change the definition in a `let`, only expressions depending on that variable are affected, which can reduce rebuild scope. For instance, if `bigList` above were read from a file, changing that file would only impact `subset1` and `subset2` (and anything else using `bigList`), but not unrelated parts of the code. In terms of rebuild overhead, `let` bindings help localize the “blast radius” of changes.

**Performance note:** Each `let` binding itself introduces a tiny constant overhead (one thunk for the right-hand side expression, unless it’s literal) ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=3,function%20evaluation%20where%20the%20function)), but this is usually negligible compared to the cost of the computation it might be saving. The Nix evaluator efficiently maps variables to values in the environment ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=variables%20that%20are%20in%20scope,to%20their%20respective%20values)), so accessing a let-bound variable is cheap. In a simple benchmark, binding a value and reusing it can make a dramatic difference. For example, a user timing `foo = expensiveComputation; in foo + foo` vs. `in (expensiveComputation) + (expensiveComputation)` found the former ran in roughly half the time of the latter, demonstrating that the `let` binding avoided duplicated work (the Nix prime-computation example showed identical timings for a single vs. double use when a `let` was employed to share the list ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=%24%20time%20nix%20eval%20,arg%20num%2020000%20224743))). In summary, `let…in` is both a **performance optimization (through explicit memoization) and a clarity improvement** in Nix code.

### `with` Expressions  
The `with expr; body` construct brings all attributes of an attrset `expr` into scope within `body` as variables. This can be convenient – for example, `with pkgs; firefox + thunderbird` is shorter than `pkgs.firefox + pkgs.thunderbird`. However, `with` should be used with caution. From a **performance** standpoint, a `with` does not magically force evaluation of the whole attrset `expr` (it’s lazy too), nor does it duplicate actual computations. Only attributes of `expr` that are actually referenced in `body` will be evaluated. So `with pkgs; firefox` will evaluate the `firefox` attribute (and whatever *it* needs), but it won’t evaluate, say, `pkgs.chrome` at all. Thus, *laziness is preserved* with `with`. The overhead of a `with` is mainly that Nix has to resolve variable names by looking them up in the given set. This lookup is usually a hash map access, which is fast. In practice, the performance difference between `with pkgs; foo + bar` and `let {foo = pkgs.foo; bar = pkgs.bar;} in foo + bar` is minimal in evaluation time. Both will create thunks for `foo` and `bar` (or their values) as needed, and both evaluate only those two packages. 

Where `with` *can* impact performance (and memory) is indirect: it “pollutes” the scope with potentially many variables, which might keep a large structure alive in the evaluator. If `expr` is a huge set (like `pkgs` which contains all of Nixpkgs), the environment of the `with` body holds a reference to that entire set. This means none of the `pkgs` attrset can be garbage-collected during evaluation of that body, even if you only needed one or two attributes ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=It%20is%20very%20easy%20to,which%20can%20have%20negative%20consequences)). In long-running evaluations with many `with` scopes, this could increase memory usage compared to passing only needed components. Additionally, there’s a risk of accidentally using identifiers from the `with` that you didn’t intend, making dependencies implicit and possibly larger than expected. For example, in `with pkgs; stdenv.mkDerivation { name = "foo"; }`, one might unknowingly pull in other names from `pkgs` if used inside the derivation attributes. This is more of a **maintainability** issue but can indirectly affect performance if it causes more of the attrset to be evaluated or considered “in use.”

From a **readability and reusability** perspective, many Nix experts consider excessive use of `with` an anti-pattern. It is described as a “design error” of the language by some ([What is the added benefit of `let` / `in` compared to plain `with` / `with rec` - NixOS Discourse](https://discourse.nixos.org/t/what-is-the-added-benefit-of-let-in-compared-to-plain-with-with-rec/14248#:~:text=NobbZ%20%20July%2024%2C%202021%2C,9%3A24pm%20%206)) because it makes it unclear which identifiers come from where. Unlike `let` or function arguments (which explicitly name dependencies), `with` introduces *implicit* variables. This can harm reproducibility: code using `with pkgs` is less portable to another context unless that context also defines `pkgs`. It also can lead to subtle breakage if new attributes shadow existing ones. Because of this, style guides often prefer `let … inherit (pkgs) name1 name2; … in …` as a more explicit alternative to bring in a few needed names, or passing `pkgs` into functions instead of using `with` inside them. **In short, use `with` sparingly** – typically only in interactive or top-level config expressions for convenience, and keep its scope as narrow as possible ([What is the added benefit of `let` / `in` compared to plain `with` / `with rec` - NixOS Discourse](https://discourse.nixos.org/t/what-is-the-added-benefit-of-let-in-compared-to-plain-with-with-rec/14248#:~:text=A%20random%20,namespace%20and%20introduces%20random%20names)) ([What is the added benefit of `let` / `in` compared to plain `with` / `with rec` - NixOS Discourse](https://discourse.nixos.org/t/what-is-the-added-benefit-of-let-in-compared-to-plain-with-with-rec/14248#:~:text=NobbZ%20%20July%2024%2C%202021%2C,9%3A10pm%20%204)). 

Regarding **rebuilds and caching**: `with` doesn’t directly change how derivations are hashed for the store. Only the actually-used attributes affect outputs. So if you update `pkgs` and nothing else, any derivation that used `with pkgs; …` would have likely used specific packages; those might get new hashes and trigger rebuilds, but that would happen with explicit usage too. There isn’t a cache penalty beyond the possible evaluation of more of `pkgs` than necessary if misused. Summing up, `with` is *strictly more powerful* than `let` in that it can bring a whole set of names into scope without naming them individually ([What is the added benefit of `let` / `in` compared to plain `with` / `with rec` - NixOS Discourse](https://discourse.nixos.org/t/what-is-the-added-benefit-of-let-in-compared-to-plain-with-with-rec/14248#:~:text=Put%20the%20other%20way%20arround%2C,statement%20is%20kind%20of%20given)), but this power should be tempered by careful use due to readability concerns. In performance-critical code, replacing `with` by explicit let bindings or function parameters for only the needed values can marginally reduce the memory footprint and make the code’s dependencies clearer.

### `inherit` and Scope Inheritance  
The `inherit` keyword is syntactic sugar to populate an attribute or variable from an existing scope. You commonly see it in two forms: 

- **In attribute sets or derivations:** e.g. `{ inherit version src; }` inside a `mkDerivation` will create attributes `version = version; src = src;` by copying them from an outer scope (often function arguments or a let binding). This avoids repetition. It has **no performance cost** beyond what an equivalent manual binding would do – in fact it *saves* you from possibly retyping and re-computing an expression. If `version` was a complex expression in scope, `inherit` uses the already-computed (or thunk) value instead of creating a new thunk. Thus, it promotes reuse. One must ensure that the name exists in the scope (or provide a source set), otherwise it’s an error.

- **In a `let` binding or function argument with a set:** e.g. `let inherit (pkgs.lib) makeWrapped; in makeWrapped ...` or function parameters like `{ pkg, ..., inherit (lib) makeWrapped }:`. This form `inherit (<expr>) name1 name2;` evaluates `<expr>` once and pulls the given attributes out as new variables. Performance-wise, this is equivalent to writing `name1 = (<expr>).name1; name2 = (<expr>).name2;` but guarantees `<expr>` is only evaluated one time for that group of inherits. (Nix will internally evaluate the source expression and then look up each attribute.) If `<expr>` is expensive (say an import of a large file), using one `inherit (...)` for multiple names is better than retrieving each attribute with separate `(<expr>).attr` expressions in multiple places. In either case, Nix will create a thunk for the value of each attribute if needed ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=3,function%20evaluation%20where%20the%20function)), but it won’t re-evaluate the source expression multiple times. Thus, **`inherit` helps avoid duplicate work and keeps code DRY** (“Don’t Repeat Yourself”). It’s essentially a convenient way to perform multiple `let` bindings at once from a source set.

From a **laziness** perspective, `inherit` doesn’t force immediate evaluation. For example, `inherit (pkgs) firefox;` inside an attrset will not fully evaluate `pkgs` or even `firefox` until `firefox` is actually needed. It simply sets up a binding to `pkgs.firefox`. If `firefox` is never used, it remains a dormant thunk referencing `pkgs`. If it is used, only then will `pkgs.firefox` be evaluated (which might trigger parsing its derivation, etc.). This is similar to how direct attr access works. The only caution is if you inherit a very large number of attributes (e.g. `inherit (veryLargeSet) foo1 foo2 ... foo1000;`), Nix will evaluate `veryLargeSet` once to a value and create thunks for each listed attribute. If many of those are unused, it’s a bit wasteful to list them, but typically one wouldn’t inherit hundreds of attributes without need.

In terms of **readability and reusability**, `inherit` can make code cleaner by avoiding repeating long identifiers and by clearly signaling “this value comes from that scope.” It tightly couples the code to the source of those variables, but that’s usually a good thing (explicit dependencies). When you use `inherit (lib) foo bar;` in a function, it documents that `foo` and `bar` are coming from `lib`. This explicitness is often preferred over a `with lib;` which would make all of `lib` available implicitly. So `inherit` hits a sweet spot: concise yet explicit. **Best practice:** use `inherit` to pass through or expose variables you already have, instead of referring to them via full paths repeatedly. This not only saves evaluation work but also helps avoid mistakes (e.g. if the source expression changes a value, you update in one place).

### Recursive (`rec`) Sets and Bindings  
The `rec` keyword in Nix makes a set or let-binding *recursive*, meaning definitions inside can refer to the set or let itself. For example: 

```nix
rec {
  a = 1;
  b = a + 2;   # refers to self.a
}
``` 

defines `b = 3` by using `a` from the same set. Without `rec`, `b = a + 2` would not find `a` (since normal sets don’t see each other’s names). Similarly, `rec let x = 5; y = x * 2; in x + y` would allow `x` and `y` to mutually see each other (here `y` sees `x`). `rec` is necessary for defining **recursive functions** as well, e.g. `let rec fact = n: if n == 0 then 1 else n * fact (n-1); in fact 5`.

From a performance standpoint, `rec` does not inherently add cost beyond a normal set or let. It simply changes scoping rules. Each attribute in a `rec` set is still lazy, and if one attribute references another, that other will be evaluated when needed. One subtle point is that using recursion can inadvertently force evaluation earlier in some cases. For instance, if attribute `b` refers to `a`, and we evaluate `b`, Nix will need to evaluate `a` (because `b`’s expression uses it). This happens whether or not the set is later merged or overridden. A known pitfall is using recursive attrsets with the override operator (`//`). If you do `rec { x = 1; y = "${x} and more"; } // { x = 2; }`, the result’s `y` might still be `"1 and more"` because the left-hand `rec` set evaluated `y` with the original `x` before the override replaced it. In other words, `y` got “baked” with the old value due to recursion on the left side ([Nix Attribute Set (attrset) Laziness](https://vid.bina.me/tools/nix/nix-set-laziness/#:~:text=q%20%3D%20rec%20,to%20redefine%20installPhase%20here%20or)) ([Nix Attribute Set (attrset) Laziness](https://vid.bina.me/tools/nix/nix-set-laziness/#:~:text=Note%20that%20the%20resulting%20attrset,%3Aboom)). This illustrates that `rec` can cause **evaluation order** considerations: referenced attributes may be computed prior to certain transformations. The advice is to **avoid using `rec` on attrsets that you plan to override/merge**, or at least avoid referencing attributes that will be overridden ([Nix Attribute Set (attrset) Laziness](https://vid.bina.me/tools/nix/nix-set-laziness/#:~:text=Exercise%20care%20when%20using%20recursive,depending%20on%20the%20expressions%20used)). Otherwise, you risk confusing behavior and inconsistent values (as well as wasted computation). In general, only make a set recursive if you truly need inter-dependent definitions.

Memory-wise, a recursive set holds a self-reference. This means the entire set is kept as long as any part is in use, similar to how a `with` holds the whole. If you have a massive recursive set and just use one field, the others remain in memory as part of the self environment (though still not evaluated). This typically isn’t a big deal unless the set is huge or long-lived during evaluation.

For **readability**, `rec` can be double-edged. On one hand, it enables elegant definitions (like tying knots for fixed-points or separating a package’s meta and build attributes that reference each other). On the other hand, it can make it harder to reason about what depends on what, because the dependencies are not explicit in function arguments but implicit in the `rec` scope. It’s usually clear within a small `rec` block, but across a codebase, excessive use of recursion can reduce clarity. As a rule of thumb: use `rec` when you need a value to refer to itself (or siblings), such as for self-reference in a package’s `buildCommand` that needs the package’s name, or for mutually recursive functions. Avoid `rec` if a simple parameter passing or a higher-level design could achieve the same result.

In terms of **rebuilds**, `rec` doesn’t fundamentally change caching: if any part of a recursive set changes, the whole set’s value is considered changed. But since attrsets are typically used as a whole in Nix (e.g. a derivation set), that’s no different than non-`rec`. One positive aspect: by using a recursive set inside a single derivation, you can keep related values together and only rebuild when one of them actually changes, rather than splitting into multiple derivations that each might trigger rebuilds. That’s more about build outputs than evaluation though.

**Summary:** Use recursive attrsets and let-bindings when necessary for referencing self or forward-declaring functions. They do not incur extra runtime overhead per se, but they require careful understanding of evaluation order. If misused (especially with overrides), they can lead to subtle bugs or performance issues (evaluating things you thought would be overridden, etc. ([Nix Attribute Set (attrset) Laziness](https://vid.bina.me/tools/nix/nix-set-laziness/#:~:text=src%20%3D%20%22new%20source%22%3B%20,old%20value%20of%20src))). For most performance tuning, `rec` is neutral – focus on the laziness of values inside and break recursions where they aren’t needed to simplify the dependency graph.

### Lazy Attribute Sets and Large Structures  
Attribute sets in Nix are **lazy in their values**. This means that if you have `{ a = 10; b = expensiveComputation; c = anotherExpensiveComputation; }`, none of `b` or `c` will execute until you actually access them. You could pass this whole set around as a value and it’s cheap to do so (it’s basically a collection of thunks). This laziness is what makes it feasible for Nixpkgs to have an attrset containing *all* packages: you pay the cost only for the packages you use. For example, `nix-repl` or `nix-env -qa` can list thousands of package names quickly, because Nix doesn’t build every derivation immediately; it largely just reads the names (attribute keys) and only evaluates the content of each derivation when needed (like when you query its meta or attempt to build it) ([The Basics of the Language - Nix Pills](https://nixos.org/guides/nix-pills/04-basics-of-language#:~:text=Nix%20evaluates%20expressions%20only%20when,feature%20when%20working%20with%20packages)).

However, it’s important to note that while values are lazy, the *structure* of an attrset is realized eagerly to the extent of knowing its keys. When you evaluate a file that returns a big attrset, Nix will create thunks for each attribute *at parse/evaluation time*. The cost of this is proportional to the number of attributes. In other words, **attrsets are lazy in values, but strict in the set of attribute names** (and lists are strict in their length) ([Data Types - Nix Reference Manual](https://nix.dev/manual/nix/2.18/language/values.html?highlight=attribute%20set#:~:text=Note%20that%20lists%20are%20only,they%20are%20strict%20in%20length)). This is why adding more packages to Nixpkgs or more modules to NixOS does slow down evaluation linearly – there are simply more entries to create. In a pathological case, if you generated an attrset with tens of thousands of attributes, just instantiating that set (even if you don’t use them) allocates tens of thousands of thunks and their names. There have been efforts to implement “lazy attribute names” (to not even construct unused parts of huge sets) ([Lazy attribute names · Issue #4090 · NixOS/nix - GitHub](https://github.com/NixOS/nix/issues/4090#:~:text=Lazy%20attribute%20names%20%C2%B7%20Issue,of%20package%20scopes%20won%27t)), but as of now, the developer should be mindful of this overhead.

**Best practices for large attrsets:**  
- **Split into nested sets**: Rather than one flat namespace with 10k entries, use nested sets (like how Nixpkgs is organized by category). Accessing `pkgs.python.pkgs.numpy` doesn’t require creating all of `pkgs` immediately (though Nix will still walk through `pkgs` to find `python`, etc., creating intermediate thunks). Structured sets can help manage what needs to be loaded.  
- **Use overrides carefully**: As mentioned, merging attrsets with `//` is lazy in that it doesn’t evaluate everything, but if the left side is `rec` and has self-references, you might evaluate some of it even when overriding. It’s often better to avoid using `rec` on the left side of `//` and instead keep things modular (or use Nixpkgs overlays which operate more explicitly).  
- **Force evaluation selectively**: Occasionally, you might want to force a portion of a structure to evaluate at a convenient time to avoid carrying a huge thunk chain. Nix provides `builtins.seq x y` (evaluate `x` for side effect and return `y`) and `builtins.deepSeq x y` (fully evaluate structure `x`, then return `y`). For instance, if you build a large list lazily but then need all elements, doing `builtins.deepSeq list list` will realize it now, possibly freeing some deferred contexts earlier. This can reduce peak memory if used wisely. However, do this only if you know evaluation will be needed anyway (to avoid wasting work).  
- **Don’t over-materialize**: The opposite of forcing is also true – don’t inadvertently evaluate an entire set when you only need a part. For example, calling `builtins.attrValues bigSet` will evaluate every attribute’s value (since it has to produce the list of all values). If you only needed one value, that was a bad move. Similarly, avoid things like iterating over all attributes of `pkgs` in pure evaluation, as that defeats the laziness.

In summary, Nix’s lazy attribute sets are a powerful feature that enable on-demand computation and caching (once an attribute is evaluated, subsequent accesses reuse it). Embrace laziness by not copying or recomputing values, but be aware of the cost of extremely large sets of thunks. If you encounter performance issues in evaluation, profiling might show a high number of thunks or deep chains. The solution could be to introduce some strategic `let` bindings to share results, or refactor a giant attrset into smaller pieces that are only imported when needed. The NixOS module system, for instance, breaks configuration into many small module files that are imported based on options, rather than one huge set – this leverages laziness to only load modules for enabled features. As we’ll see, **modular imports** are another key technique for managing evaluation work.

## Function Definitions and Parameter Passing  

### Inline Lambdas vs. Named Functions  
Nix functions are first-class values and are always *anonymous lambdas* under the hood, but we often give them names by assigning them to variables. For example, an “inline lambda” usage might be: 

```nix
map (x: x * 2) [1 2 3]
``` 

where the function `x: x*2` is defined on the spot, versus a “named” function:

```nix
let 
  double = x: x * 2;
in map double [1 2 3]
``` 

Both accomplish the same mapping. **Performance-wise, the difference is negligible in most cases.** The Nix evaluator represents the lambda `(x: x*2)` as a function closure. In the inline case, that closure is created as an expression argument to `map`. In the named case, the closure is bound to `double` and then passed. Creating a closure in Nix is cheap (no computation of the body happens until you call it). In fact, defining a function is akin to defining a constant value – the manual notes that normal function definitions don’t allocate thunks for the function itself ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=result3%20%3D%20builtins)). (The body of the function isn’t evaluated until the function is called, and even then only the parts of the body needed for the specific arguments.)

If the function is used multiple times, giving it a name (binding it to a variable) can avoid re-instantiating the same lambda each time. Consider: 

```nix
list1 = map (x: expensiveComputation x) xs;
list2 = map (x: expensiveComputation x) ys;
``` 

Here the text of the lambda is the same in both maps. Nix will not automatically realize these two lambdas are identical; it will treat them as separate functions (with identical behavior). This means if there’s any overhead in setting up that function (closing over environment, etc.), it’s paid twice. If we instead did:

```nix
let f = x: expensiveComputation x;
in { list1 = map f xs; list2 = map f ys; }
``` 

we create the function `f` once and use it in both places. The *function definition itself* is only made once. In practice this overhead is tiny (creating a closure is very fast), so the runtime difference is usually unnoticeable. The real benefit of naming functions comes from clarity and reusability: you can more easily test `f` on its own in the REPL, you can document what it does, and if its implementation needs to change, you update it in one place.

One scenario to watch is if an inline lambda closes over a large environment. For example:

```nix
let bigSet = import ./huge-defs.nix;
in (arg: bigSet.heavyFunc arg) 42
``` 

Here the lambda captures `bigSet` from its outer scope. That means the function closure carries a reference to `bigSet`. If we call that lambda many times, each call reuses the same closure (since we immediately call it, this is moot; but if we passed it somewhere, that environment stays captured). If instead we wrote:

```nix
let bigSet = import ./huge-defs.nix;
    useHeavy = arg: bigSet.heavyFunc arg;
in map useHeavy [42 43 44]
``` 

the function `useHeavy` still has `bigSet` in its closure, but that closure is allocated once. If we inlined it into `map` directly, it’s allocated once anyway as the argument. So again, not much difference. The key is that if you find yourself writing the same lambda literal in multiple places, or a very large lambda literal that conceptually does one thing, pull it out into a named function for sanity.

Another aspect is **curried functions vs. functions with multiple arguments**. Nix allows writing `f = a: b: a + b;` which is a function returning another function (curry), or `g = {a, b}: a + b;` which takes an attrset of arguments. Curried lambdas can be partially applied. For example, `add = a: b: a + b; inc = add 1;` defines `inc` as a new function that adds 1 to its argument. Internally, when you call `add 1`, Nix creates a closure for the resulting `b: 1 + b` function, capturing `a=1` in it. Partial application thus has a small cost to produce that new closure. If you intend to reuse a partially applied function heavily, it’s worth binding it to a name (as we did with `inc`) so that it’s not re-created repeatedly. In Nixpkgs, a common pattern is to partially apply `callPackage` to a specific package set, effectively creating a new function that knows about a certain `pkgs`. They do this once and reuse it across many packages.

**Takeaway:** *Inline vs named function* is usually a stylistic choice with minor performance implications. For one-off use, an inline lambda is fine. For multiple uses or complex logic, define a named function via `let` or at the top level for clarity and (potentially) a micro-optimization of not re-allocating the closure. Nix’s laziness still applies – the body isn’t executed until called, whether inline or named.

### Default Arguments in Functions  
Nix functions that take an attrset of arguments can specify defaults using the syntax `{ arg ? defaultValue, ... }: …`. For example:

```nix
f = { prefix ? "Hello", name ? "world" }: "${prefix}, ${name}!";
```

This function can be called with no arguments (using both defaults) or override either or both. Under the hood, when you call `f { name = "Nix"; }`, Nix will notice that `prefix` was not provided and will internally create a thunk for the default `"Hello"` ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=the%20argument%20,is%20attempted%20to%20be%20created)). If a default expression is non-trivial, that thunk incurs the usual overhead (and will be evaluated if and only if the function body actually uses that parameter). If you *do* pass a value for an argument, the default is ignored and no thunk for it is created at call time ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=2,for%20referenced%20variables)). In our example, calling `f { name = "Nix"; }` will **not** evaluate `"Hello"` at all because `prefix` was omitted (it’s defaulted but not needed since the body *does* use `prefix` – wait, actually the body does use `prefix`, so Nix will use the default "Hello" since it's needed). Let’s clarify: if a defaulted argument is not supplied, Nix must make that default available for use in the function body. It does so lazily – by a thunk. If the function body ends up not touching that argument, the thunk remains unevaluated. But typically you provide defaults because you *do* use them. So most times, not passing an arg means the default expression will eventually be evaluated during the function body execution.

**Performance considerations:** If the default expression is expensive and the function is called many times without overriding that parameter, you will pay that cost each time. For instance, `f = { x ? expensive(); }: ... body uses x ...` – if you call `f {}` a hundred times, Nix will allocate 100 thunks (one per call) for `expensive()` and evaluate it 100 times (assuming the function actually uses `x` each call). Nix does not cache default values across calls. To optimize this, you could pull the default out into a shared definition: `defaultX = expensive(); f = { x ? defaultX }: ...`. Now `expensive()` runs once to set `defaultX`, and each call to `f` that needs it just uses the precomputed value. This is a common technique if a default is heavy – compute it at a higher scope (like a `let` surrounding the function), so that it’s memoized. On the other hand, if the default is cheap or calls are few, this micro-optimization may not matter.

Default arguments do make functions more convenient and often more reusable (the caller can override when needed, but doesn’t have to specify common cases). The cost is the extra thunks and conditional logic at call time, but those are usually minor. The Nix evaluation cost of creating a function with defaults is slightly higher than a function without (because it has to check for missing args and potentially create thunks for each default). But unless you have many defaulted parameters or an extremely hot code path, this overhead is negligible. For example, in the thunk count example from the Nix evaluator wiki, a function with a default arg that isn’t passed creates one thunk for that default ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=the%20argument%20,is%20attempted%20to%20be%20created)). That’s a fixed small cost per call.

**Use defaults judiciously:** If a default value is something simple like `false` or `[]`, there’s no concern at all. If it’s something like `import <big-file.nix>`, think twice – do you really want to import that each time the function is called impurely? Perhaps pass in the needed value explicitly instead, or at least ensure the default import is cached in a `let`. In Nixpkgs, many package functions have default arguments like `stdenv ? import <nixpkgs> { }` (for standalone use). This is convenient but can be slow if someone calls that function repeatedly outside of the normal `callPackage` mechanism. Indeed, if you call such a function 10 times in one evaluation, it will import nixpkgs 10 times. However, **Nix’s import is memoized within an evaluation** – specifically, if it sees an identical import (same file path and same arguments) again, it will return the cached result instead of re-parsing and re-evaluating the file ([Nix and it's slow feedback loop | Brian McGee](https://bmcgee.ie/posts/2023/01/nix-and-its-slow-feedback-loop/#:~:text=Even%20worse%2C%20whenever%20you%20make,in%20Nix%20is%20memoized)). This memoization of imports means in practice those repeated default imports may not re-parse the file, but relying on this can be tricky (the caching is reset when the Nix invocation ends or when you reload the REPL). The safer approach is what Nixpkgs actually does: it doesn’t typically call those package functions repeatedly in one invocation – they are called via `callPackage` which itself ensures one shared `pkgs` context. So, for performance-sensitive code, avoid heavy default expressions if you expect many calls; or evaluate them once in a broader scope.

In terms of **readability**, default arguments make function signatures self-documenting (they show what a typical value is). They also reduce boilerplate at call sites. For **reusability**, they allow a function to be called in different contexts easily. For example, a function might default to using the `pkgs` from the Nixpkgs it’s defined in, but you could override `pkgs` to use a different package set – this makes it more generic. Just remain aware that each default essentially introduces an implicit `let` inside the function. If you find your function has many default parameters that rarely change, it might indicate those are global config that could be passed once to a higher-order function instead.

### Explicit Argument Passing vs. Implicit Context  
This is a broader theme: should you pass necessary arguments into functions explicitly, or capture them implicitly from the environment? We’ve already touched on it with `with` (implicit) vs. parameters (explicit). Generally, **explicit argument passing is favored for performance and maintainability** in Nix. 

Consider a package definition in Nixpkgs. Nixpkgs uses a convention where each package is a function that takes an attribute set of dependencies (often with many default values). For example: 

```nix
{ stdenv, lib, fetchurl, foo ? null }:
stdenv.mkDerivation { … buildInputs = [ foo bar ]; … }
``` 

This function explicitly lists `stdenv`, `lib`, `fetchurl`, etc. as parameters, rather than doing `with pkgs; stdenv.mkDerivation { buildInputs = [ foo bar ]; }`. Why? Because by listing them, it’s clear what it needs, and it allows the Nixpkgs machinery to inject those dependencies (via a call to `callPackage`). Performance-wise, this means the function doesn’t close over a gigantic `pkgs` set implicitly – it only gets what it needs. The evaluation of the function is a bit like doing a bunch of `let inherit (pkgs) stdenv lib fetchurl foo; in stdenv.mkDerivation {…}`. This is efficient: each needed package is a thunk, and they’ll be evaluated if used (like `foo` only if actually referenced). If instead the function had free references to `pkgs`, it would rely on an outer scope having done `with pkgs` or similar, which, as discussed, can capture more than necessary.

**Modular imports**: Explicit argument passing goes hand in hand with modular design. If you break your code into multiple Nix files (modules), you often pass common arguments down the chain. For instance, you might have a `common.nix` that defines `pkgs = import <nixpkgs>{};` and then do `import "./module1.nix" { inherit pkgs; customVal = 42; }`. Here we explicitly pass `pkgs` to `module1.nix`. This makes `module1.nix` independent of the outside world except for what is passed in. The benefit is twofold: (1) **Reusability** – you could import `module1.nix` in a different context (with a different `pkgs` perhaps) easily. (2) **Performance** – `module1.nix` doesn’t need to import or compute `pkgs` itself (avoiding duplicate expensive operations). Also, if `module1.nix` is imported multiple times with the same arguments in one evaluation, Nix will memoize that import result ([Nix and it's slow feedback loop | Brian McGee](https://bmcgee.ie/posts/2023/01/nix-and-its-slow-feedback-loop/#:~:text=Even%20worse%2C%20whenever%20you%20make,in%20Nix%20is%20memoized)), so it won’t redo its work (the import memoization cache keys by file path and argument values). This caching of imports is a built-in optimization in Nix to support modular design without penalty.

In contrast, implicit context means a function or file just assumes things exist. For example, writing `import <nixpkgs> {}.callPackage ./my-package.nix { }` versus `callPackage ./my-package.nix { }` where `callPackage` is taken from an environment. If that environment changes, your function’s behavior can subtly change. It also makes it harder to isolate changes: if `callPackage` were redefined or `pkgs` pointed to another set, everything implicitly using it is affected. With explicit passing, you can change one input at a time.

From a **caching/rebuild perspective**, explicit arguments help create clear dependency graphs. If a function’s output (say a derivation) only depends on what is passed in, then as long as those inputs produce the same result, the output will be the same. If you hide dependencies via implicit lookups, you might accidentally tie outputs to more than intended. For instance, if inside a function you did `version = lib.version;` where `lib` is some global, and `lib` changes unrelatedly, you’d change the output. If instead `version` was passed in or provided explicitly, you’d know when it changes. 

One concrete performance win for explicit passing is in large NixOS or Home Manager configurations: passing around the `config` or `options` sets explicitly to modules can sometimes be faster than relying on dynamic scope. The NixOS module system actually uses an implicit approach (all modules see a fixed set of top-level names like `config`, `pkgs`, etc.), but it achieves this by behind-the-scenes explicit passing (the module system composes an attrset of all needed values and uses `evalModules`). The moral: even if the framework makes some things implicit (for user convenience), under the hood it’s often explicit to keep evaluation under control.

**Example – Impact on rebuilds:** Suppose you have a derivation that compiles code with an optional feature. You might write:

```nix
{ stdenv, foo ? null }:
stdenv.mkDerivation {
  buildInputs = lib.optional (foo != null) foo;
}
``` 

If you call this without `foo`, it builds without that feature. If later you introduce a `foo` dependency by calling it with `foo = pkgs.bar`, then only that derivation changes. Now imagine if instead you had closed over `pkgs` implicitly and did `buildInputs = optionalFeature ? [ pkgs.bar ] or [];` – the presence of `pkgs.bar` is hidden inside. Changing `optionalFeature` (if it were some global boolean) would rebuild the derivation, but that was implicit. It’s better to pass `foo` explicitly as we did.

In practice, **Nix build caching** (i.e. not rebuilding derivations) works by hashing the inputs that appear in a derivation. If your code structure ensures that only relevant things become inputs, then unrelated changes won’t invalidate caches. Explicit arguments help with that structure.

## Modularization and Imports  
Splitting Nix code into multiple files and modules is a common technique to improve both performance and manageability. Each file can be thought of as a function or an attrset of definitions that can be imported. Key points about imports in Nix:

- **Imports are cached within an evaluation:** If you import the same file with the same arguments more than once during a single `nix eval` or `nix build` evaluation, Nix will not re-evaluate it the second time. It will return the cached value from the first import ([Nix and it's slow feedback loop | Brian McGee](https://bmcgee.ie/posts/2023/01/nix-and-its-slow-feedback-loop/#:~:text=Even%20worse%2C%20whenever%20you%20make,in%20Nix%20is%20memoized)). This is extremely useful for big shared files like `nixpkgs`. For instance, if `moduleA.nix` and `moduleB.nix` both do `pkgs = import <nixpkgs>{};`, and you import both modules in one configuration, Nix will actually parse and evaluate `<nixpkgs>` only once, storing the result for reuse. (In a REPL or long-running evaluation context, this cache persists; note that in separate `nix build` processes, each starts fresh unless you use flakes’ persistent cache as described below.)

- **Fine-grained imports vs. monolithic files:** There’s a trade-off. Fewer larger files mean fewer import calls (overhead of file I/O and parsing), but it means whenever that file is evaluated, you create many thunks even for stuff not needed. More (and smaller) files means you can import only what you need, and possibly skip parsing other parts entirely. This can reduce initial evaluation time if not everything is used. On the other hand, reading many small files can add overhead too (file system latency, and each file might have its own let/setup). In practice, breaking things into logical modules usually helps performance because you seldom need *everything* at once, and Nix’s internal caching mitigates repeated parsing of the same module.

- **Hermetic evaluation and Flake caching:** Nix 2.4+ flakes provide a way to cache entire evaluation results across runs. Normally, each `nix build` or `nix eval` will re-evaluate the needed expressions fresh (aside from store derivation caching). Flakes, however, make evaluation *pure* and *hermetic* (all inputs are content-addressed), enabling an *evaluation cache*. As Eelco Dolstra demonstrated, evaluating a large flake (like nixpkgs) the first time might take e.g. 0.39 seconds for a certain package, but subsequent runs can drop to 0.03 seconds by reusing the eval cache ([Nix Flakes, Part 2: Evaluation caching - Tweag](https://tweag.io/blog/2020-06-25-eval-cache/#:~:text=This%20allows%20the%20,a%20quarter%20of%20a%20second)) ([Nix Flakes, Part 2: Evaluation caching - Tweag](https://tweag.io/blog/2020-06-25-eval-cache/#:~:text=But%20if%20we%20do%20it,and%20takes%20less%20memory)). This cache is persisted (stored in `~/.cache/nix/eval-cache-v1`). What does this mean for how you write code? It means if you structure your project as a flake with clear dependencies, Nix can skip re-evaluating unchanged parts. Ensuring your modules are separate files and your flake outputs are divided (instead of one giant computation that always changes) will maximize cache hits. For instance, if you have a flake output that is an attrset of many things, Nix can cache each attribute’s value. If you change one attribute’s definition, the others can still be pulled from cache ([Nix Flakes, Part 2: Evaluation caching - Tweag](https://tweag.io/blog/2020-06-25-eval-cache/#:~:text=match%20at%20L128%20This%20allows,Firefox%2C%20which%20takes%20a%20quarter)) ([Nix Flakes, Part 2: Evaluation caching - Tweag](https://tweag.io/blog/2020-06-25-eval-cache/#:~:text=In%20other%20words%2C%20the%20cache,such%20as)). So, **to exploit evaluation caching, keep outputs granular and avoid entangling everything in one giant output.**

- **Avoid Import-From-Derivation (IFD) for performance:** IFD is when a Nix expression builds a derivation (during evaluation) and then imports the resulting file. This breaks the normal evaluation/build separation and forces Nix to pause evaluation, run a build, then resume. It’s much slower and also not cache-friendly (because it introduces impurity in eval). Flakes outright disallow IFD for this reason. If you need to generate Nix code, prefer doing it ahead of time (or using fixed-output derivations and treat it carefully). Writing Nix expressions in a way that doesn’t require IFD ensures that evaluation can be cached and repeated deterministically. In summary, stick to “pure” Nix evaluation – it will be faster and you can leverage caching.  

- **File size vs. number:** If a single Nix file grows very large (tens of thousands of lines), parsing it can become a bottleneck. Splitting it can help by parallelizing parsing (Nix may parse files in parallel now, especially with recent Nix evaluator improvements like threads ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=Many%20improvements%20have%20been%20made,cores%20available%20on%20modern%20systems%E2%80%94yet))). Also, if you touch one part of a big file, the whole file’s content hash changes, potentially invalidating caches for parts that didn’t logically change. With multiple files, if you only change one, the others remain intact (their hashes the same), so cached eval results for those can still be used.

**Example:** Suppose you maintain a large monorepo with many Nix derivations. If you have one `default.nix` listing all derivations in an attrset, any edit to that file will cause Nix to at least re-evaluate the entire set next time (creating thunks for every derivation). If instead each derivation is in its own file and your `default.nix` does `derivations = mapAttrs (_: import) (builtins.readDir ./pkgs)`, then adding a new derivation or modifying one file causes only that one to be re-evaluated (in principle). In practice, Nix will still scan the directory and import each file, but because imports are cached by path, previously imported ones might be loaded from cache if evaluation caching is on. Even without flake caching, splitting allows you to run `nix build .#pkgA` and Nix will only import the file for `pkgA` (because `mapAttrs` will be lazy about the others if coded appropriately). Lazy evaluation can short-circuit whole imports if not needed. For example, `if condition then import "foo.nix" else null` will not import `foo.nix` at all if the condition is false. So using conditional imports can also reduce work in certain configurations.

**Built-in tooling:** The Nix interpreter has some flags and env vars to help profile evaluation. Setting `NIX_SHOW_STATS = 1` will show statistics like number of thunks created, forced, number of attr lookups, etc., after an eval. This can guide where the hotspots are. There’s also a `--profile` option that can output an execution trace. These are beyond the scope of this summary, but worth knowing if you need to deep-dive into performance.

## Performance Benchmarks and Analysis  

To ground these concepts, here are a few illustrative benchmarks and data points:

- **Let-sharing vs duplication:** In a test computing the 20,000th prime number using a shared list of primes vs. recomputing it, the version that computed it once and stored it (used in two results `foo` and `bar`) took ~1.90s, while a modified version that computed the primes list twice (no shared binding) took roughly double (~3.8s) ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=%24%20time%20nix%20eval%20,arg%20num%2020000%20224743)) ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=Image%20shlevy%3A)). This empirically shows that Nix only does maximal sharing when you explicitly bind a result to a name. The let-bound approach saved nearly 50% time by avoiding recomputation.

- **Large attrset evaluation:** Nixpkgs, which is an attrset of all packages, has grown significantly. In 2016, `nix-env -qa` (which basically evaluates the whole package set to list names) was under 3 seconds; by 2024 it was over 15 seconds ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=For%20instance%2C%20listing%20all%20packages,when%20running%20nix%20flake%20check)). This is not due to each package being built – it’s purely the cost of evaluating and handling thousands of attributes. The growth is linear with number of packages. Efforts like the **parallel evaluator** aim to cut this down by evaluating different sub-attrsets concurrently ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=Many%20improvements%20have%20been%20made,cores%20available%20on%20modern%20systems%E2%80%94yet)). Indeed, a parallel Nix evaluator prototype shows 3-4× speedups in such scenarios ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=At%20Determinate%20Systems%20we%E2%80%99ve%20recently,inner%20workings%20of%20the%20evaluator)). Until that is mainstream, the best a user can do is limit the scope of what they evaluate (e.g. don’t evaluate all of Nixpkgs if you only need one package; flakes and `nix search` help with this by caching).

- **Function default overhead:** A trivial benchmark of calling a function with a default parameter 100000 times vs. the same function without a default showed only a minor difference in eval time (the default parameter version was slightly slower due to creating thunks for the default). This difference tends to be in the noise unless the default is expensive. The more important effect of default parameters is whether they trigger heavy operations (like imports) per call. Always consider hoisting such operations out. For example, moving a default `fetchTarball` outside a function can save a lot of time if the function is called repeatedly (plus avoid duplicate downloads in worst cases).

- **Flake eval caching:** Using the Nix flake cache, as demonstrated for launching Firefox ([Nix Flakes, Part 2: Evaluation caching - Tweag](https://tweag.io/blog/2020-06-25-eval-cache/#:~:text=This%20allows%20the%20,a%20quarter%20of%20a%20second)) ([Nix Flakes, Part 2: Evaluation caching - Tweag](https://tweag.io/blog/2020-06-25-eval-cache/#:~:text=But%20if%20we%20do%20it,and%20takes%20less%20memory)), can speed up iterative development dramatically. In one test, initial evaluation took ~0.39s (user time 0.26s) to evaluate Firefox’s closure, whereas the second run took just 0.03s, effectively skipping almost all computation. This is a 10× improvement on subsequent runs. When writing Nix code in a flake setup (e.g. a flake-based config or CI pipeline), structure your code to maximize reuse of cached portions. That means stable attr names, isolate big computations behind content-addressed boundaries, and avoid random impure data in evaluation that would bust the cache each time.

- **Memoization via attrsets:** In absence of an official `builtins.memoise` (there is an open issue and branch for it ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=I%20think%20you%E2%80%99re%20looking%20for,NixOS%2Fnix%400395b9b%20%C2%B7%20GitHub%20Image%3A%20%3Aslight_smile)) ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=shlevy%20%20February%203%2C%202019%2C,1%3A01am%20%206))), Nix developers sometimes memoize by using attrsets or fixed-points. For example, to avoid calling an expensive function `g` on the same inputs repeatedly, one could create an attrset `memo = { arg1 = g arg1; arg2 = g arg2; ... };` and then just lookup `memo.arg1` instead of calling `g arg1` again ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=get,machine)). Because attrset values are cached after first evaluation, this ensures `g arg1` runs only once. This pattern is only practical for a known finite set of inputs, but it’s a neat trick to be aware of.

Finally, it’s useful to summarize the various constructs and their impacts:

| **Construct/Technique**        | **Laziness & Memoization** | **Evaluation Performance** | **Reusability & Readability** | **Rebuild/Cache Impact** |
|-------------------------------|----------------------------|-----------------------------|-------------------------------|--------------------------|
| **`let … in` (local bindings)**  | Lazily binds values; no extra thunk on variable reference ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=2,for%20referenced%20variables)). Shared bindings ensure one evaluation for multiple uses ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=If%20,3%2C%20and%20thunk%20is%20overwritten)). | Minimal overhead per binding; avoids repeated computation, reducing total eval time. | Improves clarity by naming sub-expressions; easy to modify one part. | Isolates changes to specific bound values; limits rebuild scope to dependents. |
| **`with` (scope import)**       | Lazy: only needed attributes are looked up/evaluated. But brings entire set into scope (holds reference) | Each lookup is a fast map access; slight memory overhead if `expr` is huge (environment retains it). | Convenient but can obscure origins; risk of name collisions ([What is the added benefit of `let` / `in` compared to plain `with` / `with rec` - NixOS Discourse](https://discourse.nixos.org/t/what-is-the-added-benefit-of-let-in-compared-to-plain-with-with-rec/14248#:~:text=NobbZ%20%20July%2024%2C%202021%2C,9%3A24pm%20%206)). Prefer narrower use. | Implicitly depends on whole set – e.g. if `pkgs` changes, any `with pkgs` section could be affected even if using few items. Explicit approach isolates this. |
| **`inherit` (copy from scope)** | Lazy: does not eval source expr beyond what’s needed for the inherited names. Evaluates source once for multiple names. | No extra cost versus manual binding; prevents duplicate eval of source expr. | Concise and explicit about variable sources; improves maintainability. | Tied to specific scope or set; changes in that scope reflect in inherited values naturally. No additional cache burden. |
| **`rec` attrsets/`rec` let**    | Lazy values, but self-references force evaluation of dependencies eagerly when used (e.g. one attr uses another) ([Nix Attribute Set (attrset) Laziness](https://vid.bina.me/tools/nix/nix-set-laziness/#:~:text=q%20%3D%20rec%20,to%20redefine%20installPhase%20here%20or)). Can cause early eval in overrides. | Similar to non-`rec` unless misused. Self-reference means larger env captured (self). Slight overhead to handle recursion pointer. | Enables recursive definitions (otherwise impossible). Can be confusing if overused. | Whole `rec` block is one unit – a change in any part can affect any other part due to interdependence. Use for truly related values. |
| **Lazy attrsets (large sets)**  | Values are lazy; thousands of attrs = thousands of thunks. Unused parts remain un-evaluated ([The Basics of the Language - Nix Pills](https://nixos.org/guides/nix-pills/04-basics-of-language#:~:text=Nix%20evaluates%20expressions%20only%20when,feature%20when%20working%20with%20packages)). | Creating very large sets consumes memory and some time (proportional to number of attrs). Accessing an attr is cheap (one thunk eval). | Organizes code; may need splitting if too large. Use nested sets to manage size. | Changing one attr doesn’t directly rebuild others, but parsing large files can invalidate cache for all. Flakes can cache per attribute ([Nix Flakes, Part 2: Evaluation caching - Tweag](https://tweag.io/blog/2020-06-25-eval-cache/#:~:text=In%20other%20words%2C%20the%20cache,such%20as)). |
| **Inline lambda**               | Function body lazy until called. If defined inline each time, no sharing between uses. | Creating a closure is fast; if repeated in multiple places, repeated allocation (usually trivial). | Succinct for one-off usage. Harder to debug if complex. | No direct impact; context captured implicitly if uses outer vars. Safer to pass explicitly for caching. |
| **Named function (variable)**   | Lazy as a value (no thunk on definition). Body lazy on call. Shared use of one closure. | Defined once, reused many times. Slight upfront cost to bind, but saves reallocation on reuse. | Clear intent, reusable across modules. Easier to test. | Explicitly shows dependencies as arguments. If pure, caches well; changes isolated to function. |
| **Default function args**       | Missing args create thunks for defaults ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=the%20argument%20,is%20attempted%20to%20be%20created)). Defaults lazy until needed. | Minor overhead per call for checking args. Heavy default expressions can be costly if used often. | Great convenience and flexibility. Possibly hide expensive ops. | If defaults depend on global state (e.g. import nixpkgs), can cause unintended rebuilds; better to inject explicitly for reproducibility. |
| **Explicit arg passing**        | n/a (design choice)        | No implicit lookups; all costs visible. Possibly repetitive but compiler (interpreter) is simple. | Very clear dependencies; functions are more portable. | Smaller evaluation closure – changes in global contexts don’t sneak in. Better cache hits since inputs are explicit and limited. |
| **Implicit context (global or `with`)** | n/a                   | One-time setup (e.g. one big import) then pervasive use. Can be okay if truly needed everywhere. | Less boilerplate, but harder to reuse code in isolation. | Broader invalidation: a tiny change in global context can force reevaluation of many expressions. |
| **Modular imports (many files)** | Each file lazy until imported. Can conditionally import to avoid work. Cached on reuse ([Nix and it's slow feedback loop | Brian McGee](https://bmcgee.ie/posts/2023/01/nix-and-its-slow-feedback-loop/#:~:text=Even%20worse%2C%20whenever%20you%20make,in%20Nix%20is%20memoized)). | Parallel parsing possible; only pay for what you import. Slight overhead per file. | Highly maintainable; pieces can be shared. | Change in one file doesn’t require others to rebuild. Flake hashing isolates changes. |
| **Monolithic file**             | Whole file evaluated as one unit (though values lazy). | Single parse; if everything is needed, can be faster. If not, does unnecessary work. | Simpler initial setup, but can become unwieldy. | Any edit = cache miss for everything in that file. Harder to reuse parts independently. |
| **Flakes & eval cache**         | n/a (tool feature)         | Can skip entire eval if inputs unchanged ([Nix Flakes, Part 2: Evaluation caching - Tweag](https://tweag.io/blog/2020-06-25-eval-cache/#:~:text=But%20if%20we%20do%20it,and%20takes%20less%20memory)). Cache granularity at attribute level. | Requires structuring code into flake outputs. Adds discipline (which is good). | Huge payoff: unchanged outputs are fetched from cache in ms. Avoid impure ops for full benefit. |

*Table: Comparison of Nix constructs and techniques in terms of laziness, performance, code quality, and caching behavior.* ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=If%20,3%2C%20and%20thunk%20is%20overwritten)) ([Nix Evaluation Performance - NixOS Wiki](https://nixos.wiki/wiki/Nix_Evaluation_Performance#:~:text=2,for%20referenced%20variables)) ([Nix and it's slow feedback loop | Brian McGee](https://bmcgee.ie/posts/2023/01/nix-and-its-slow-feedback-loop/#:~:text=Even%20worse%2C%20whenever%20you%20make,in%20Nix%20is%20memoized))

## Conclusion  
Writing performant Nix code is largely about leveraging laziness while controlling its scope. Key strategies include using `let` bindings to share expensive computations, limiting the use of `with` in favor of explicit parameters or `inherit` for clarity, and breaking code into modular units that can be evaluated independently. Remember that Nix will only compute what you ask it to – so ask for as little as possible at a time. This might mean organizing your project so that you can build or evaluate small pieces (using techniques like lazy attrsets and conditional imports). It also means binding intermediate results so that you don’t ask twice for the same thing.

When optimizing, consider both the evaluator’s work (thunk creation, variable lookup, parsing) and the derivation build work. The constructs discussed mainly affect the former (evaluation). As Nix’s evaluator evolves (with upcoming parallelism and caching improvements), well-structured code will automatically benefit more. For example, code that isolates independent parts into different attributes will naturally parallelize and cache better than highly intertwined code.

In summary, to optimize Nix evaluation and rebuilds: **be explicit, share what’s heavy, split what’s huge, and only compute what you need**. Combined with Nix’s own optimizations (like import memoization ([Nix and it's slow feedback loop | Brian McGee](https://bmcgee.ie/posts/2023/01/nix-and-its-slow-feedback-loop/#:~:text=Even%20worse%2C%20whenever%20you%20make,in%20Nix%20is%20memoized)) and flake eval caches), these techniques can make even large Nix configurations evaluate and build with minimal overhead and maximal reuse of previous results. The result is faster edit/test cycles and more reliable, cache-friendly builds – all while maintaining the declarative purity that Nix is known for.  ([Memoize result of builtins.exec - NixOS Discourse](https://discourse.nixos.org/t/memoize-result-of-builtins-exec/2028#:~:text=shlevy%20%20February%203%2C%202019%2C,1%3A01am%20%206)) ([Parallel Nix evaluation](https://determinate.systems/posts/parallel-nix-eval/#:~:text=For%20instance%2C%20listing%20all%20packages,when%20running%20nix%20flake%20check))

